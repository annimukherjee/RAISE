{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, torch\n",
    "\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"]  = \"1\"   \n",
    "os.environ[\"MKL_NUM_THREADS\"]  = \"1\"   \n",
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n",
    "\n",
    "torch.set_deterministic_debug_mode(True)\n",
    "\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"   # or \":4096:8\" for big convs\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)         \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "torch.use_deterministic_algorithms(True)   \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch and related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# For splitting and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import random; import numpy as np; import torch\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 1) Load CSV and stratified split data\n",
    "\n",
    "test_df = pd.read_csv(\"../../dataset/ratings/test.csv\")\n",
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image dimensions\n",
    "HEIGHT, WIDTH = 384, 512\n",
    "\n",
    "# For validation and testing we only need to convert to tensor.\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMOSDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame with columns 'filename' and 'MOS'\n",
    "            img_dir (str): Directory with all the images.\n",
    "            transform: torchvision transforms to apply to images.\n",
    "        \"\"\"\n",
    "\n",
    "        missing = [f for f in dataframe['filename'] if not os.path.isfile(os.path.join(img_dir, f))]\n",
    "        assert not missing, f\"Missing image files: {missing[:5]}…\"\n",
    "\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image filename and full path\n",
    "        filename = self.dataframe.loc[idx, 'filename']\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        # Open image and ensure it is RGB\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "\n",
    "        # Get the normalized MOS value as a float tensor\n",
    "        mos = torch.tensor(self.dataframe.loc[idx, 'MOS'], dtype=torch.float32)\n",
    "\n",
    "        assert isinstance(image, torch.Tensor)\n",
    "        assert image.shape == (3, HEIGHT, WIDTH), f\"Got shape {image.shape}\"\n",
    "        assert  torch.isfinite(mos), \"MOS is not finite\"\n",
    "\n",
    "\n",
    "        return image, mos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in test dataset: 90\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = ImageMOSDataset(test_df,  \"../../dataset/images/test_images/\", transform=eval_transforms)\n",
    "\n",
    "print(f\"Number of images in test dataset: {len(test_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # Create DataLoaders\n",
    "\n",
    "\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    # guarantees that each DataLoader worker reproduces its own stream\n",
    "    worker_seed = SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    torch.manual_seed(worker_seed)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,          \n",
    "    generator=g,\n",
    "    worker_init_fn=worker_init_fn  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "SimpleCNN(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block5): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # First convolutional block\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # (384x512 → 192x256)\n",
    "        )\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # → 96x128\n",
    "        )\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # → 48x64\n",
    "        )\n",
    "\n",
    "        # Fourth convolutional block\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # → 24x32\n",
    "        )\n",
    "        \n",
    "        # Fifth convolutional block (added)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # → 12x16\n",
    "        )\n",
    "\n",
    "        # Global average pooling instead of flattening\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)  # Output: 256x1x1\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 256)\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.manual_seed(SEED)\n",
    "\n",
    "# Instantiate the model and send to device (GPU if available)\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/8h7869116bj2w59cq06rwl8c0000gn/T/ipykernel_10170/1310131689.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint_path)  # or \"cuda:0\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"./weights/baseCNN_2025-05-25_time_00-51-37_SROCC_62_Pearson_69.pth\"    # your .pth file\n",
    "state_dict = torch.load(checkpoint_path)  # or \"cuda:0\"\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 434,817\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f\"Total number of trainable parameters: {num_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SROCC:    0.6216\n",
      "Pearson:  0.6944\n",
      "R^2:      0.4593\n",
      "MAE: 0.5105\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        # Detach and move to CPU; flatten the predictions.\n",
    "        preds = outputs.cpu().numpy().flatten()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Compute Spearman's rank correlation coefficient (SROCC)\n",
    "spearman_corr, _ = spearmanr(all_labels, all_preds)\n",
    "\n",
    "# Compute Mean Absolute Error (MAE)\n",
    "mae_val = mean_absolute_error(all_labels, all_preds)\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(all_labels, all_preds)\n",
    "# Compute R² score\n",
    "r2_val = r2_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"SROCC:    {spearman_corr:.4f}\")\n",
    "print(f\"Pearson:  {pearson_corr:.4f}\")\n",
    "print(f\"R^2:      {r2_val:.4f}\")\n",
    "print(f\"MAE: {mae_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_realness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
